{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  \n",
    "from PIL import ImageEnhance  \n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "#将传入的灰度图二值化\n",
    "def tow_value(imgry):\n",
    "    max = 0\n",
    "    gray = 0\n",
    "    data =[]\n",
    "    for i in imgry.getcolors():\n",
    "        if i[0]>max:\n",
    "            max = i[0]\n",
    "            gray = i[1]\n",
    "        if i[0] < 42:\n",
    "            data.append(i[1])\n",
    "    data.append(gray)\n",
    "    def get_bin_table(data):\n",
    "        table = []\n",
    "        for i in range(256):\n",
    "            if i in data:\n",
    "                table.append(1)\n",
    "            else:\n",
    "                table.append(0)\n",
    "\n",
    "        return table\n",
    "\n",
    "    table = get_bin_table(data)\n",
    "    out = imgry.point(table, '1')\n",
    "    return out\n",
    "\n",
    "def depoint(img):\n",
    "    \"\"\"传入二值化后的图片进行降噪\"\"\"\n",
    "    pixdata = img.load()\n",
    "    w,h = img.size\n",
    "    for y in range(1,h-1):\n",
    "        for x in range(1,w-1):\n",
    "            count = 0\n",
    "            if pixdata[x,y-1] == 0:#上\n",
    "                count = count + 1\n",
    "            if pixdata[x,y+1] == 0:#下\n",
    "                count = count + 1\n",
    "            if pixdata[x-1,y] == 0:#左\n",
    "                count = count + 1\n",
    "            if pixdata[x+1,y] == 0:#右\n",
    "                count = count + 1\n",
    "            if pixdata[x-1,y-1] == 0:#左上\n",
    "                count = count + 1\n",
    "            if pixdata[x-1,y+1] == 0:#左下\n",
    "                count = count + 1\n",
    "            if pixdata[x+1,y-1] == 0:#右上\n",
    "                count = count + 1\n",
    "            if pixdata[x+1,y+1] == 0:#右下\n",
    "                count = count + 1\n",
    "            if count > 4:\n",
    "                pixdata[x,y] = 0\n",
    "    return img\n",
    "\n",
    "def vectorize(j):\n",
    "    '''\n",
    "    将数字字母转换成one-hot向量\n",
    "    如： 2 => [0,0,1,0,0,0,0,0,0,0...] 长度为62 \n",
    "    '''\n",
    "    vector = np.zeros((62, 1))\n",
    "    if '0' <= j <= '9':\n",
    "        vector[ord(j)-48] = 1.0\n",
    "    elif 'A' <= j <= 'Z':\n",
    "        vector[ord(j)-55] = 1.0\n",
    "    else:\n",
    "        vector[ord(j)-61] = 1.0\n",
    "    return vector\n",
    "\n",
    "#将切割后的图片信息转换一下\n",
    "def trans_image(cropped_image):\n",
    "    a = np.array(cropped_image)\n",
    "    data = []\n",
    "    #遍历切割图片的矩阵，转换切割图片的信息\n",
    "    for i in range(30):\n",
    "        for j in range(30):\n",
    "            if a[i][j]:\n",
    "                data.append(1)\n",
    "            else:\n",
    "                data.append(0)\n",
    "    return np.reshape(data,(900,1))\n",
    "\n",
    "#加载文件信息并将文件处理成训练模型所需要的数据形式\n",
    "\n",
    "def load_data(path):\n",
    "    all_data=[]\n",
    "    labels = []\n",
    "    lsdir = os.listdir(path)\n",
    "    if path == 'train':\n",
    "        for jpg in lsdir:\n",
    "            image = Image.open(r'train/'+jpg)\n",
    "            imgry = image.convert('L')  # 转化为灰度图\n",
    "            out = tow_value(imgry) #将灰度图二值化\n",
    "            im =  depoint(out) #将二值化后的图片降噪\n",
    "            #将图片切割\n",
    "            cropped_image_1 = im.crop((0, 0, 30, 30))\n",
    "            cropped_image_2 = im.crop((30, 0, 60, 30))\n",
    "            cropped_image_3 = im.crop((60, 0, 90, 30))\n",
    "            cropped_image_4 = im.crop((90, 0, 120, 30))\n",
    "            cropped_image_5 = im.crop((120, 0, 150, 30))\n",
    "            all_data.append(trans_image(cropped_image_1))\n",
    "            all_data.append(trans_image(cropped_image_2))\n",
    "            all_data.append(trans_image(cropped_image_3))\n",
    "            all_data.append(trans_image(cropped_image_4))\n",
    "            all_data.append(trans_image(cropped_image_5))\n",
    "            labels.append(vectorize(jpg[0]))\n",
    "            labels.append(vectorize(jpg[1]))\n",
    "            labels.append(vectorize(jpg[2]))\n",
    "            labels.append(vectorize(jpg[3]))\n",
    "            labels.append(vectorize(jpg[4]))\n",
    "        return list(zip(all_data,labels))\n",
    "    else:\n",
    "        for jpg in range(20000):\n",
    "            image = Image.open(r'test/'+str(jpg)+'.jpg')\n",
    "            imgry = image.convert('L')  # 转化为灰度图\n",
    "            out = tow_value(imgry) #将灰度图二值化\n",
    "            im =  depoint(out) #将二值化后的图片降噪\n",
    "              #将图片切割\n",
    "            cropped_image_1 = im.crop((0, 0, 30, 30))\n",
    "            cropped_image_2 = im.crop((30, 0, 60, 30))\n",
    "            cropped_image_3 = im.crop((60, 0, 90, 30))\n",
    "            cropped_image_4 = im.crop((90, 0, 120, 30))\n",
    "            cropped_image_5 = im.crop((120, 0, 150, 30))\n",
    "            all_data.append(trans_image(cropped_image_1))\n",
    "            all_data.append(trans_image(cropped_image_2))\n",
    "            all_data.append(trans_image(cropped_image_3))\n",
    "            all_data.append(trans_image(cropped_image_4))\n",
    "            all_data.append(trans_image(cropped_image_5))\n",
    "        return all_data\n",
    "           \n",
    "            \n",
    "train_data = load_data('train')\n",
    "test_data = load_data('test')\n",
    "print('执行完毕')\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"sizes包含各层神经元的数目，比如如果sizes=[2,3,1]说明此神经网络\n",
    "        共有三层，每一层的神经元数目分别为2，3，1.权重和偏置根据标准正态分\n",
    "        布随机初始化，第一层为输入神经元，没有偏置\"\"\"\n",
    "        self.num_layers = len(sizes)#层数\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]#偏置，随机初始化，标准正态分布\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]#权重，随机初始化，标准正态分布\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"返回结果\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"使用小批量随机训练神经网络\n",
    "         梯度下降。 ``training_data``是一个元组列表\n",
    "         ``（x，y）``代表训练输入和期望的\n",
    "        输出。 其他非可选参数是\n",
    "        不言自明的。 如果提供了``test_data``则\n",
    "         每次之后，都会根据测试数据评估网络\n",
    "         迭代，并打印出部分进度。 这对于\n",
    "         跟踪进度，但会大大降低进度\"\"\"\n",
    "        training_data = list(training_data)\n",
    "#         test_data = list(test_data)\n",
    "        if test_data: n_test = len(test_data)#如果提供测测试集，每个epoch后进行评估\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)#每个epoch随机打乱训练集，保证随机性\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test))#随时监控程序运行情况，可以删掉\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"更新权重和偏置，eta表示学习率\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]#初始化偏置\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]#初始化权重\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"反向传播算法，返回梯度，先不要管.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"评估预测正确的个数\n",
    "            np.argmax函数返回数组的最大值的序号，实现从one-hot到数字的转换；\n",
    "        \"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"反向传播中用到的计算偏导数，先不要管\"\"\"\n",
    "        return (output_activations-y)\n",
    "\n",
    "    def predict(self,test_data):\n",
    "        '''预测函数'''\n",
    "        predict = []\n",
    "        print(self.biases)\n",
    "        print(self.weights)\n",
    "        for x in test_data:\n",
    "            p = np.argmax(self.feedforward(x))\n",
    "            if 0<= p <= 9:\n",
    "                predict.append(str(p))\n",
    "            elif 10 <= p <= 35:\n",
    "                predict.append(chr(p+55))\n",
    "            else:\n",
    "                predict.append(chr(p+61))\n",
    "        return predict\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"S型函数\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"反向传播中用到的.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "net = Network([900,100,62])\n",
    "net.SGD(train_data,30,500,2.0)#30个迭代期，小批量为150，学习率3.0\n",
    "print('训练完毕')\n",
    "\n",
    "#生成预测结果\n",
    "pre = net.predict(test_data)\n",
    "predict = []\n",
    "for i in range(0,100000,5):\n",
    "    predict.append(pre[i]+pre[i+1]+pre[i+2]+pre[i+3]+pre[i+4])\n",
    "\n",
    "#将预测结果写入csv文件\n",
    "index = range(0,predict.__len__()+1)\n",
    "headers = ['id','y']\n",
    "rows = list(zip(index,predict))\n",
    "with open('predict.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
